2011.05.18.12.34.00

Задача 1. У Луганова там exec-перенаправление используется, за это, скорее
всего два плюсика. У Вас же решение стандартное. Awk, diff и прочее - это,
конечно, замечательно, но первая задача вообще-то была на тему сопроцессов.
Вот если вы своё решение средствами Bash переработаете с использованием
coproc, то поставлю Вам три плюсика.

Задача 2. Нужно выводить pid и gpid у процесса, во время получения сигнала.
Остальные параметры - по желанию, но, конечно, дополнительный + за то, что
вы их обрабатываете. Но printf в обработчике сигнала, цикл вечного ожидания,
ненадёжный флаг для выхода - to_exit, вызов из test.sh gcc в апострофах -
за всё это минусы. Мы же обсуждали, как это надо делать. Хотя бы sigpause 
использовали.

Задача 4.(-1). Неплохо, но есть существенные недочёты. Во-первых, нужно увидеть
в man read то, что в случае достижения конца файла возвращается 0, нет смысла
продолжать его читать.

Во-вторых, если я напишу так:

	(echo 123 && sleep 1h) | ./descriptors 0 4 4<test.sh

то программа ведёт себя мистически.

	1. Почему-то она прекращает работу с 0 дескриптором после таймаута.
	А если бы я написал нечто такое:

		echo 123 && sleep 1h && echo 456
	
	это же вполне нормальное поведение, для медленного ползователя,
	который данные выдаёт с большим интервалом. А мы договаривались, что
	программа должна выводить данные, пока они могут быть в потоке. А для
	этого poll должен обрабатывать сразу множество дескрипторов файлов,
	и программа не должна обрываться по таймауту.

	2. Хм... Хорошо, поправьте пока пункт 1, может быть, автоматически и
	это замечание исправлено будет Вами.

2011.05.25.22.33.05

Задача 1. Про сопроцессы. Я наивно предполагал, что люди решат второй файл,
с более сложной структурой, фильтровать через некий конвейер, чтобы получить
такую же равномерную структуру, как и в первом файле, чтобы одним и тем же
кодом их загружать. Но, видимо, слишком простой оказалась структура.

Но. Если бы некто решил использовать pipe, то получилось бы что? Если написать
так:

	convert | our | complex | stream | while read hash size filename; do
		array[$filename]=...
	done

то while бы запустился в от-fork-аном процессе со своим адрессным пространством
и array был бы заполнен в этом пространстве, а в исходном оставался бы пустым.

Сопроцессы, кроме того, что работают параллельно с основным bash-потоком
исполнения, позволяют поток данных из конвейера завернуть обратно в
адресное пространство основного bash-процесса

	coproc filter { convert | our | comples | stream; }

	while ...; do array[...]=...; done <&$filter[0]

Тогда array заполняется в исходном адресном пространстве, и конвейер получается
завёрнутым обратно.

Задача 3. Если Вы хотите THIS FIXED ORDER! то надо писать volatile. Эх...
Оптимизирует же компилятор. Это во-первых. Во-вторых, если честно, я с трудом
понимаю логику. Или даже совсем не понимаю. У вас какие-то названия странные.
Чем current generation от current wrap отличается? И вот не ясно. Допустим даже
такой сценарий исполнения (G - поток пересчёта, P - поток печати)

	G.1 Успешно выставляет свой LOCK, меняет указатели местами и начинает
	считать из текущего в следующий

	P.1 Ждёт, пока расчёт не будет закончен в цикле while(!CAS...),
	выставив перед этим first penetration (в чём глубинный смысл названия?)
	в 1.

	G.2 Делает UNLOCK, засыпает (ну, допустим... и почему ваша группа так
	любит активное ожидание? - загадочно).

	P.2 Зависает во втором while на целую секунду, пока G не обнаружит
	LOCK на текущем буфере, не пойдёт по второй ветке, где обнаружит
	ожидание, поправит src и зачем-то запишет UNLOCK в current wrap.

Я верно понимаю эту конструкцию? При этом first penetration всегда выставляется,
и всегда поток P ожидает обновления src... Хм. Что я упускаю из виду? Если
ничего не упускаю, то это пока не является решением задачи, потому как в
условии требовалось, чтобы на печать выводился текущее состояние, а не то,
которое будет получено через секунду.

А вообще, CAS же - мощная штука. Если уж Вы её используйте, то используйте по
делу, меняйте и читайте с её помощью указатель на следующий свободный буфер.
Тут бы такое использование было самым эффективным. Подумайте над этим.

С другой стороны, не бойтесь операционной системы. Примитивы синхронизации в
ней реализованы очень эффективно. И lock-free с циклами ожидания синхронизация
(кстати, если есть while(!CAS...), то это уже не wait-free), гораздо менее
эффективна, особенна в системах, где работает множество процессов. Вот сняли
одну нить с выполнения, чтобы другим дать поработать, а вы в цикле впустую
циклитесь, ожидая, когда она свой CAS выполнит. Зачем?

Это даже при разработке игр не особо оправдано, потому что лучше отдать
процессоры обсчитывающим, скажем, физику нитям, чем безидейно зависать в
цикле.

2011.05.28.09.59.58

Задачи 5 и 5.(+1) За технику исполнения дополнительный плюс, но вот, оно
пока не работает. Я изменил COUNTER_LIMIT, сделал его равным 500000, и теперь...

	 $ clang -D_GNU_SOURCE -O4 dekker.c -o dkr -lpthread 
	 $ ./dkr 
	 counter=1000000
	 $ ./dkr 
	 counter=500000
	 $ ./dkr 
	 counter=500000
	 $ ./dkr 
	 counter=500000
	 $ ./dkr 
	 counter=1000000

Ну, вроде, понятно. Без mfence должно наблюдаться некое ошибочное поведение. Но,
настолько регулярное? Это загадочно. Почему так? Объясните.

Далее. Если я включаю опцию WITH_MFENCE:

	$ clang -DWITH_MFENCE -D_GNU_SOURCE -O4 dekker.c -o dkr -lpthread 
	$ ./dkr
	counter=998848

Опять что-то не так.
